{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install numpy -q\n",
    "%pip install pandas -q\n",
    "%pip install matplotlib -q\n",
    "%pip install networkx -q\n",
    "%pip install torch -q\n",
    "%pip install torch_geometric -q\n",
    "%pip install tqdm -q\n",
    "%pip install scipy -q\n",
    "%pip install scikit-learn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Third-party imports\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "import torch_geometric\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.utils import degree\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unzip dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted to data/interim/\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "file = 'data/raw/ml-100k.zip'\n",
    "target_dir = 'data/interim/'\n",
    "\n",
    "with zipfile.ZipFile(file, 'r') as zip_ref:\n",
    "    zip_ref.extractall(target_dir)\n",
    "\n",
    "print(f\"Successfully extracted to {target_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_data():\n",
    "    ml_100k_folder = 'data/interim/ml-100k/'\n",
    "\n",
    "    user_file = 'u.user'\n",
    "    item_file = 'u.item'\n",
    "    data_file = 'u.data'\n",
    "    genre_file = 'u.genre'\n",
    "    info_file = 'u.info'\n",
    "    occupation_file = 'u.occupation'\n",
    "\n",
    "    # column names\n",
    "    user_cols = ['user_id', 'age', 'gender', 'occupation', 'zip_code']\n",
    "    item_cols = ['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url']\n",
    "    data_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "\n",
    "    # Load data into Pandas DataFrames\n",
    "    users = pd.read_csv(os.path.join(ml_100k_folder, user_file), sep='|', names=user_cols)\n",
    "    items = pd.read_csv(os.path.join(ml_100k_folder, item_file), sep='|', names=item_cols, encoding='latin-1')\n",
    "    data = pd.read_csv(os.path.join(ml_100k_folder, data_file), sep='\\t', names=data_cols)\n",
    "\n",
    "    genre = pd.read_csv(os.path.join(ml_100k_folder, genre_file), sep='|', header=None, names=['genre_id', 'genre'])\n",
    "    info = pd.read_csv(os.path.join(ml_100k_folder, info_file), sep=' ', header=None, names=['info'])\n",
    "    occupation = pd.read_csv(os.path.join(ml_100k_folder, occupation_file), header=None, names=['occupation'])\n",
    "\n",
    "\n",
    "    return users, items, data, genre, info, occupation\n",
    "\n",
    "\n",
    "users_df, items_df, ratings_df, genre_df, info_df, occupation_df = load_data()\n",
    "\n",
    "# Print the first few rows of each DataFrame to verify the data loading\n",
    "print(\"Users DataFrame:\")\n",
    "print(users_df.head())\n",
    "\n",
    "print(\"\\nItems DataFrame:\")\n",
    "print(items_df.head())\n",
    "\n",
    "print(\"\\nRatings DataFrame:\")\n",
    "print(ratings_df.head())\n",
    "\n",
    "print(\"\\nGenre DataFrame:\")\n",
    "print(genre_df)\n",
    "\n",
    "print(\"\\nInfo DataFrame:\")\n",
    "print(info_df)\n",
    "\n",
    "print(\"\\nOccupation DataFrame:\")\n",
    "print(occupation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic data preprocessing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
